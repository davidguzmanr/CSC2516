# CSC2516: How Does Data Augmentation Affect Differential Privacy in Deep Learning?
Final project for CSC2516 Winter 2023 Neural Networks and Deep Learning

> **How Does Data Augmentation Affect Differential Privacy in Deep Learning?**<br>
> David Guzm√°n<sup>1</sup>, Abraham Morales<sup>2</sup>, Rui Xian<sup>2</sup><br>
> <sup>1</sup>Department of Computer Science, <sup>2</sup>Department of Statistical Sciences<br>
>
> <p align="justify"><b>Abstract:</b> <i>Data augmentation is a technique used to generate new training examples from existing data to improve the robustness and generalization of deep learning models, while differential privacy is a technique used to preserve the privacy of individual data points while releasing statistical information about a dataset. Here we study the relationship between data augmentation and differential privacy in deep learning, and the possible tradeoffs they may offer between the success rate of membership inference attacks, total differential privacy cost and general model accuracy. While differential privacy techniques applied to the deep learning framework, and there have been studies on the privacy cost for data augmentation algorithms; to the best of our knowledge, no other work has explored these two together.</i></p>